{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ddb1d8-fc41-44ba-864c-5c7c9a1e0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukul/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa41fcc8-2fa9-4bf0-b678-7fa7fe377033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "042e3f65-5f7c-434f-b2f3-29aa72f7907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b236897a-4b4c-4099-8ecb-2eb2db582f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [5.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b5b9a25-74f5-4760-b006-e0c629e7c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ba73007-d132-4b95-88a6-648cf27946fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the attention input tensor: torch.Size([4, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "batch_size = 4        # Number of samples in a batch\n",
    "sequence_length = 10  # Length of the sequence\n",
    "d_model = 64          # Dimensionality of the token embeddings\n",
    "\n",
    "# Create the tensor\n",
    "attention_input = torch.randn(batch_size, sequence_length, d_model)\n",
    "\n",
    "# Print the shape of the tensor to confirm\n",
    "print(\"Shape of the attention input tensor:\", attention_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b06f2256-73f2-4497-b8f9-0f8fe5fa8256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 16])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, d_model = attention_input.size()\n",
    "\n",
    "attention_input.view(batch_size, seq_len, 4, 16).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cbbd0d1-73d7-4f19-99eb-439504c98c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 10, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_input.view(batch_size, seq_len, 4, 16).transpose(1, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4c2aa38-9017-4048-8992-d6855eb1cb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 64])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_input.view(batch_size, seq_len, d_model).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "200f0d88-90a4-4407-a19f-eac9b49b7796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - torch.triu(torch.ones(1, 10, 10), diagonal=1)).bool()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
