{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ddb1d8-fc41-44ba-864c-5c7c9a1e0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukul/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa41fcc8-2fa9-4bf0-b678-7fa7fe377033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "042e3f65-5f7c-434f-b2f3-29aa72f7907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b236897a-4b4c-4099-8ecb-2eb2db582f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [5.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b5b9a25-74f5-4760-b006-e0c629e7c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ba73007-d132-4b95-88a6-648cf27946fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the attention input tensor: torch.Size([4, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "batch_size = 4        # Number of samples in a batch\n",
    "sequence_length = 10  # Length of the sequence\n",
    "d_model = 64          # Dimensionality of the token embeddings\n",
    "\n",
    "# Create the tensor\n",
    "attention_input = torch.randn(batch_size, sequence_length, d_model)\n",
    "\n",
    "# Print the shape of the tensor to confirm\n",
    "print(\"Shape of the attention input tensor:\", attention_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b06f2256-73f2-4497-b8f9-0f8fe5fa8256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 16])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, d_model = attention_input.size()\n",
    "\n",
    "attention_input.view(batch_size, seq_len, 4, 16).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cbbd0d1-73d7-4f19-99eb-439504c98c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 10, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_input.view(batch_size, seq_len, 4, 16).transpose(1, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4c2aa38-9017-4048-8992-d6855eb1cb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 64])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_input.view(batch_size, seq_len, d_model).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "200f0d88-90a4-4407-a19f-eac9b49b7796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - torch.triu(torch.ones(1, 10, 10), diagonal=1)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e371e6a-e410-416c-9c48-891a51a46156",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = torch.randint(1, 5000, (64, 100))\n",
    "tgt_data = torch.randint(1, 5000, (64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24d09dac-19be-438f-9eaf-286e47949ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2184, 3921,  206, 2447, 4460, 3794,  496, 1418, 2315, 1153,  326, 1285,\n",
       "        2583, 2464, 2769, 2948, 2379,  947, 4036, 4491, 3275,  435, 1740,  709,\n",
       "         602,  284, 3625,   64,  457, 2345, 1666, 4523, 2594, 3960, 3339,  742,\n",
       "        1362, 3352,  975, 3854, 1110, 2316,  697,  101, 4558, 3913, 2906, 4456,\n",
       "        3741, 4972, 1046, 4379, 1583, 2290,   12,  670,  456, 1235, 1802, 3937,\n",
       "        4734, 3278,  168, 2799,  621, 1151, 3956, 4439, 4400,  148, 4551,  138,\n",
       "        1998,  246, 2498,  983, 1296, 2383, 4575,  638, 4197, 4456, 3200, 1336,\n",
       "        3469, 1929, 1509, 3307, 1138, 3999,  533, 2386, 4216, 4719, 2318, 4958,\n",
       "         704, 4604, 2880])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_data[:, :-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb41a36b-096b-4ff6-bccd-d2156f6432b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 512])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "emb = nn.Embedding(5000, 512)\n",
    "emb(src_data).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
